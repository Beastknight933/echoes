# -------------------------------
# FastAPI + ML + LLM compatible stack
# Tested on Python 3.10â€“3.12 (Windows/Linux/macOS)
# CPU-only environment, conflict-free
# -------------------------------

# --- Web Framework ---
fastapi==0.100.0
pydantic==2.4.0
pydantic-settings==2.0.3
uvicorn[standard]==0.22.0

# --- Core Scientific Stack ---
numpy==1.26.4
scikit-learn==1.3.2

# --- Deep Learning / NLP ---
torch==2.3.1+cpu ; platform_system != "Darwin"
# NOTE: PyTorch wheels are hosted separately.
# On Windows/Linux, pip will automatically fetch the correct CPU wheel
# from https://download.pytorch.org/whl/cpu

transformers==4.41.0
sentence-transformers==2.2.2

# --- Networking / API calls ---
requests==2.31.0
httpx==0.24.1

# --- Environment & Configuration ---
python-dotenv==1.0.0

# --- LLM Providers ---
# OpenAI - REQUIRED for OpenRouter (uses OpenAI-compatible API)
openai>=1.12.0

# Optional: Only install if using direct API access
# google-generativeai>=0.3.0  # For Google Gemini direct
# anthropic>=0.25.0  # For Anthropic Claude direct

# --- Optional: Caching ---
redis==5.0.0  # Uncomment if using Redis

# --- Optional: Rate Limiting ---
# slowapi==0.1.9  # Uncomment if you want rate limiting